---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/main/helmrelease-helm-v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app local-ai
spec:
  interval: 30m
  chart:
    spec:
      # renovate: registryUrl=https://go-skynet.github.io/helm-charts/
      chart: local-ai
      version: 3.4.2
      sourceRef:
        kind: HelmRepository
        name: go-skynet
        namespace: flux-system
  maxHistory: 3
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    replicaCount: 1
    deployment:
      image:
        repository: quay.io/go-skynet/local-ai
        tag: v2.25.0-aio-gpu-intel-f32
      env:
        debug: true
        threads: 4
        context_size: 512
    lifecycle:
      postStart:
        exec:
          command:
            - /bin/bash
            - -c
            - >
              apt install libclblast-dev ocl-icd-libopencl1 -y &&
              mkdir /tmp/neo &&
              cd /tmp/neo &&
              wget https://github.com/intel/intel-graphics-compiler/releases/download/v2.5.6/intel-igc-core-2_2.5.6+18417_amd64.deb &&
              wget https://github.com/intel/intel-graphics-compiler/releases/download/v2.5.6/intel-igc-opencl-2_2.5.6+18417_amd64.deb &&
              wget https://github.com/intel/compute-runtime/releases/download/24.52.32224.5/intel-level-zero-gpu-dbgsym_1.6.32224.5_amd64.ddeb &&
              wget https://github.com/intel/compute-runtime/releases/download/24.52.32224.5/intel-level-zero-gpu_1.6.32224.5_amd64.deb &&
              wget https://github.com/intel/compute-runtime/releases/download/24.52.32224.5/intel-opencl-icd-dbgsym_24.52.32224.5_amd64.ddeb &&
              wget https://github.com/intel/compute-runtime/releases/download/24.52.32224.5/intel-opencl-icd_24.52.32224.5_amd64.deb &&
              wget https://github.com/intel/compute-runtime/releases/download/24.52.32224.5/libigdgmm12_22.5.5_amd64.deb &&
              dpkg -i *.deb
    resources:
      requests:
        gpu.intel.com/i915: 1
      limits:
        gpu.intel.com/i915: 1

    models:
      forceDownload: false
      list:
        - url: "https://gpt4all.io/models/ggml-gpt4all-j.bin"

    persistence:
      models:
        enabled: true
        annotations: {}
        storageClass: ceph-block
        accessModes:
          - ReadWriteOnce
        size: 50Gi
        globalMount: /models

      output:
        enabled: true
        annotations: {}
        accessModes:
          - ReadWriteOnce
        size: 10Gi
        storageClass: ceph-block
        globalMount: /tmp/generated

    service:
      type: LoadBalancer
      ports:
        http:
          port: 8080

    ingress:
      enabled: true
      ingressClassName: internal
      annotations:
        external-dns.alpha.kubernetes.io/target: internal.ktmb1.net
      hosts:
        - host: &host local-ai.${SECRET_DOMAIN}
          paths:
            - path: /
              pathType: Prefix
